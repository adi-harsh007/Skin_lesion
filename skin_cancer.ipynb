{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Skin Cancer Classification (HAM10000)\n",
    "## Binary Classification: Benign vs Malignant\n",
    "### Using only HAM10000_images_part_1 with class imbalance handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/6th SEM/Minor Project/skin_cancer/skin_cancer/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_path = \"archive/HAM10000_metadata.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Total samples in metadata: {len(metadata)}\")\n",
    "print(f\"\\nClass distribution in original data:\")\n",
    "print(metadata['dx'].value_counts())\n",
    "\n",
    "# Create binary labels: Malignant (1) vs Benign (0)\n",
    "# Malignant: mel (melanoma), bcc (basal cell carcinoma), akiec (actinic keratoses)\n",
    "# Benign: nv (melanocytic nevi), bkl (benign keratosis), df (dermatofibroma), vasc (vascular lesions)\n",
    "malignant_types = ['mel', 'bcc', 'akiec']\n",
    "metadata['binary_label'] = metadata['dx'].apply(lambda x: 1 if x in malignant_types else 0)\n",
    "\n",
    "print(f\"\\nBinary class distribution:\")\n",
    "print(metadata['binary_label'].value_counts())\n",
    "print(f\"Benign: {(metadata['binary_label'] == 0).sum()}\")\n",
    "print(f\"Malignant: {(metadata['binary_label'] == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only images that exist in part_1\n",
    "image_dir = \"archive/HAM10000_images_part_1\"\n",
    "available_images = set([f.replace('.jpg', '') for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
    "\n",
    "print(f\"Total images in part_1: {len(available_images)}\")\n",
    "\n",
    "# Filter metadata to only include images from part_1\n",
    "metadata_part1 = metadata[metadata['image_id'].isin(available_images)].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nFiltered samples: {len(metadata_part1)}\")\n",
    "print(f\"\\nClass distribution in part_1:\")\n",
    "print(f\"Benign: {(metadata_part1['binary_label'] == 0).sum()}\")\n",
    "print(f\"Malignant: {(metadata_part1['binary_label'] == 1).sum()}\")\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "benign_count = (metadata_part1['binary_label'] == 0).sum()\n",
    "malignant_count = (metadata_part1['binary_label'] == 1).sum()\n",
    "imbalance_ratio = benign_count / malignant_count\n",
    "print(f\"\\nClass imbalance ratio (Benign/Malignant): {imbalance_ratio:.2f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets (stratified)\n",
    "train_df, val_df = train_test_split(\n",
    "    metadata_part1, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=metadata_part1['binary_label']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"  Benign: {(train_df['binary_label'] == 0).sum()}\")\n",
    "print(f\"  Malignant: {(train_df['binary_label'] == 1).sum()}\")\n",
    "\n",
    "print(f\"\\nValidation samples: {len(val_df)}\")\n",
    "print(f\"  Benign: {(val_df['binary_label'] == 0).sum()}\")\n",
    "print(f\"  Malignant: {(val_df['binary_label'] == 1).sum()}\")\n",
    "\n",
    "# Reset indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-header",
   "metadata": {},
   "source": [
    "## 3. Create Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinLesionDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.image_dir, f\"{row['image_id']}.jpg\")\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = row['binary_label']\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transforms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Transforms created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = SkinLesionDataset(train_df, image_dir, transform=train_transform)\n",
    "val_dataset = SkinLesionDataset(val_df, image_dir, transform=val_transform)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "# Test loading one sample\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "print(f\"\\nSample image shape: {sample_image.shape}\")\n",
    "print(f\"Sample label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-weights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for handling imbalance\n",
    "train_labels = train_df['binary_label'].values\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "print(f\"Class weights: Benign={class_weights[0]:.4f}, Malignant={class_weights[1]:.4f}\")\n",
    "\n",
    "# These weights will be used in the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-loaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 4. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinCancerClassifier(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(SkinCancerClassifier, self).__init__()\n",
    "        # Load pretrained ResNet18\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Replace final layer for binary classification\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Initialize model\n",
    "model = SkinCancerClassifier(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model created successfully\")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with class weights to handle imbalance\n",
    "pos_weight = class_weights[1] / class_weights[0]\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]).to(device))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', patience=3, factor=0.5, verbose=True\n",
    ")\n",
    "\n",
    "print(f\"Loss function: BCEWithLogitsLoss with pos_weight={pos_weight:.4f}\")\n",
    "print(f\"Optimizer: Adam (lr=0.0001)\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().to(device).unsqueeze(1)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predictions = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().to(device).unsqueeze(1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Track metrics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predictions = (probs > 0.5).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Store for detailed metrics\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_labels, all_preds, all_probs\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 20\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# History tracking\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Store metrics\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_skin_cancer_model.pth')\n",
    "        print(f\"âœ“ Best model saved! (Val Acc: {val_acc:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 7. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(history['val_loss'], label='Val Loss', marker='o')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "ax2.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(history['val_acc'], label='Val Accuracy', marker='o')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 8. Evaluate Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-best-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_skin_cancer_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions on validation set\n",
    "val_loss, val_acc, all_labels, all_preds, all_probs = validate_epoch(\n",
    "    model, val_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_probs = np.array(all_probs).flatten()\n",
    "\n",
    "print(f\"Final Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    all_labels, \n",
    "    all_preds, \n",
    "    target_names=['Benign', 'Malignant'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=['Benign', 'Malignant'],\n",
    "    yticklabels=['Benign', 'Malignant'],\n",
    "    cbar_kws={'label': 'Count'},\n",
    "    annot_kws={'size': 14, 'weight': 'bold'}\n",
    ")\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "auc_score = roc_auc_score(all_labels, all_probs)\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
    "print(\"ROC curve saved as 'roc_curve.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 9. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Dataset: HAM10000_images_part_1\")\n",
    "print(f\"Total samples: {len(metadata_part1)}\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}:1 (Benign:Malignant)\")\n",
    "print(f\"Imbalance Handling: Class-weighted loss function\")\n",
    "print(f\"\\nModel: ResNet18 (pretrained)\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(\"\\nModel saved as: best_skin_cancer_model.pth\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
